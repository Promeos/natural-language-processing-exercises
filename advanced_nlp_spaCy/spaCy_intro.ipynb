{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Advanced NLP with spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the English language class from spacy\n",
    "from spacy.lang.en import English"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The __English__ class object includes language-specific rules for tokenization: words, numbers, and punctuation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate an English NLP object\n",
    "nlp = English()\n",
    "\n",
    "doc = nlp(\"This is an introductory lesson to spaCy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Documents, spans, and tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tree kangaroos\n",
      "tree kangaroos and narwhals\n"
     ]
    }
   ],
   "source": [
    "# Process the text\n",
    "doc = nlp(\"I like tree kangaroos and narwhals.\")\n",
    "\n",
    "# A slice of the Doc for \"tree kangaroos\"\n",
    "tree_kangaroos = doc[2:4]\n",
    "print(tree_kangaroos.text)\n",
    "\n",
    "# A slice of the Doc for \"tree kangaroos and narwhals\" (without the \".\")\n",
    "tree_kangaroos_and_narwhals = doc[2:6]\n",
    "print(tree_kangaroos_and_narwhals.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokens and Characters\n",
    "Accessing words in variable `doc`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This is an introductory lesson to spaCy'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Access the entire string using the `.text` attribute.\n",
    "doc.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "This"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using index notation to access the first token.\n",
    "doc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Span Object\n",
    "Using index notation on an English/nlp object returns a span object. This is merely a __view__ of the document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "This is an"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using index notation to view the first 3 tokens of the document.\n",
    "doc[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using index notation with `.text` attribute to access the first 4 characters of the document.\n",
    "doc.text[0:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lexical Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index:    [0, 1, 2, 3, 4, 5, 6]\n",
      "Index:    ['This', 'is', 'an', 'introductory', 'lesson', 'to', 'spaCy']\n"
     ]
    }
   ],
   "source": [
    "# Print the index of each token in the document.\n",
    "print(\"Index:   \", [token.i for token in doc])\n",
    "\n",
    "# Print each token in the document.\n",
    "print(\"Index:   \", [token.text for token in doc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lexical Conditional Operators\n",
    "- doc`.is_alpha` returns True if the token contains all characters, False otherwise.\n",
    "- doc`.is_punct` returns True if the token is punctuation, False otherwise.\n",
    "- doc`.like_num` returns True if the token is a digit or numeric word, i.e. \"Ten\". False otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new `doc` variable for this example.\n",
    "doc_lexi = nlp(\"There were ten houses priced at $10,000,000 dollars. You bought 5. How much did it cost?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is_alpha: [True, True, True, True, True, True, False, False, True, False, True, True, False, False, True, True, True, True, True, False]\n"
     ]
    }
   ],
   "source": [
    "# Determine if a token is homogenously composed of alpha characters.\n",
    "print(\"is_alpha:\", [token.is_alpha for token in doc_lexi])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is_punct: [False, False, False, False, False, False, False, False, False, True, False, False, False, True, False, False, False, False, False, True]\n"
     ]
    }
   ],
   "source": [
    "# Determine if a token is a punctuation character.\n",
    "print(\"is_punct:\", [token.is_punct for token in doc_lexi])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "like_num: [False, False, True, False, False, False, False, True, False, False, False, False, True, False, False, False, False, False, False, False]\n"
     ]
    }
   ],
   "source": [
    "# Determine if a token is like a number.\n",
    "print(\"like_num:\", [token.like_num for token in doc_lexi])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import other languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Liebe Grüße!\n",
      "¿Cómo estás?\n"
     ]
    }
   ],
   "source": [
    "# Import the Spanish, German classifiers spacy.lang.es, spacy.lang.de\n",
    "from spacy.lang.es import Spanish\n",
    "from spacy.lang.de import German\n",
    "\n",
    "# German and Spanish\n",
    "nlp_german = German()\n",
    "nlp_spanish = Spanish()\n",
    "\n",
    "# Instantiate german and spanish nlp objects\n",
    "doc_german = nlp_german(\"Liebe Grüße!\")\n",
    "doc_spanish = nlp_spanish(\"¿Cómo estás?\")\n",
    "\n",
    "# Print each word in the doc\n",
    "print(doc_german.text)\n",
    "print(doc_spanish.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
