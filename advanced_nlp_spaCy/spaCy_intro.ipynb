{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Advanced NLP with spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the English language class from spacy\n",
    "import spacy\n",
    "from spacy.lang.en import English"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The __English__ class object includes language-specific rules for tokenization: words, numbers, and punctuation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate an English NLP object\n",
    "nlp = English()\n",
    "\n",
    "doc = nlp(\"This is an introductory lesson to spaCy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Documents, spans, and tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tree kangaroos\n",
      "tree kangaroos and narwhals\n"
     ]
    }
   ],
   "source": [
    "# Process the text\n",
    "doc = nlp(\"I like tree kangaroos and narwhals.\")\n",
    "\n",
    "# A slice of the Doc for \"tree kangaroos\"\n",
    "tree_kangaroos = doc[2:4]\n",
    "print(tree_kangaroos.text)\n",
    "\n",
    "# A slice of the Doc for \"tree kangaroos and narwhals\" (without the \".\")\n",
    "tree_kangaroos_and_narwhals = doc[2:6]\n",
    "print(tree_kangaroos_and_narwhals.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokens and Characters\n",
    "Accessing words in variable `doc`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I like tree kangaroos and narwhals.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Access the entire string using the `.text` attribute.\n",
    "doc.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "I"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using index notation to access the first token.\n",
    "doc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Span Object\n",
    "Using index notation on an English/nlp object returns a span object. This is merely a __view__ of the document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "I like tree"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using index notation to view the first 3 tokens of the document.\n",
    "doc[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I li'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using index notation with `.text` attribute to access the first 4 characters of the document.\n",
    "doc.text[0:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import other languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Liebe Grüße!\n",
      "¿Cómo estás?\n"
     ]
    }
   ],
   "source": [
    "# Import the Spanish, German classifiers spacy.lang.es, spacy.lang.de\n",
    "from spacy.lang.es import Spanish\n",
    "from spacy.lang.de import German\n",
    "\n",
    "# German and Spanish\n",
    "nlp_german = German()\n",
    "nlp_spanish = Spanish()\n",
    "\n",
    "# Instantiate german and spanish nlp objects\n",
    "doc_german = nlp_german(\"Liebe Grüße!\")\n",
    "doc_spanish = nlp_spanish(\"¿Cómo estás?\")\n",
    "\n",
    "# Print each word in the doc\n",
    "print(doc_german.text)\n",
    "print(doc_spanish.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lexical Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index:    [0, 1, 2, 3, 4, 5, 6]\n",
      "Index:    ['I', 'like', 'tree', 'kangaroos', 'and', 'narwhals', '.']\n"
     ]
    }
   ],
   "source": [
    "# Print the index of each token in the document.\n",
    "print(\"Index:   \", [token.i for token in doc])\n",
    "\n",
    "# Print each token in the document.\n",
    "print(\"Index:   \", [token.text for token in doc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lexical Conditional Operators\n",
    "- doc`.is_alpha` returns True if the token contains all characters, False otherwise.\n",
    "- doc`.is_punct` returns True if the token is punctuation, False otherwise.\n",
    "- doc`.like_num` returns True if the token is a digit or numeric word, i.e. \"Ten\". False otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new `doc` variable for this example.\n",
    "doc_lexi = nlp(\"There are ten houses priced at $10,000,000 dollars. You bought 5. How much did it cost?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is_alpha: [True, True, True, True, True, True, False, False, True, False, True, True, False, False, True, True, True, True, True, False]\n"
     ]
    }
   ],
   "source": [
    "# Determine if a token is homogenously composed of alpha characters.\n",
    "print(\"is_alpha:\", [token.is_alpha for token in doc_lexi])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is_punct: [False, False, False, False, False, False, False, False, False, True, False, False, False, True, False, False, False, False, False, True]\n"
     ]
    }
   ],
   "source": [
    "# Determine if a token is a punctuation character.\n",
    "print(\"is_punct:\", [token.is_punct for token in doc_lexi])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "like_num: [False, False, True, False, False, False, False, True, False, False, False, False, True, False, False, False, False, False, False, False]\n"
     ]
    }
   ],
   "source": [
    "# Determine if a token is like a number.\n",
    "print(\"like_num:\", [token.like_num for token in doc_lexi])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage found: 60\n",
      "Percentage found: 4\n"
     ]
    }
   ],
   "source": [
    "# Example from spaCy docs\n",
    "nlp = English()\n",
    "\n",
    "# Process the text\n",
    "doc = nlp(\n",
    "    \"In 1990, more than 60% of people in East Asia were in extreme poverty. \"\n",
    "    \"Now less than 4% are.\"\n",
    ")\n",
    "\n",
    "# Iterate over the tokens in the doc\n",
    "for token in doc:\n",
    "    # Check if the token resembles a number\n",
    "    if token.like_num:\n",
    "        # Get the next token in the document, view the next token\n",
    "        next_token = doc[token.i+1]\n",
    "        # Check if the next token's text equals \"%\"\n",
    "        if next_token.text == \"%\":\n",
    "            # If a percentage is next to a number like token, return the numeric token.\n",
    "            print(\"Percentage found:\", token.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical Models\n",
    "\n",
    "__`spaCy`__'s statisitcal models allow a user to predict lingustical attributes in _context_.\n",
    "- Part-of-speech tags `token.pos_`\n",
    "- Syntactic dependencies\n",
    "- Named entities\n",
    "\n",
    "These models are trained large datasets on labeled example texts and can be updates with more examples to fine-tune predictions, i.e. your specific data.\n",
    "\n",
    "`en_core_web_sm` is a small English model trained on web text.\n",
    "- Contains binary weights of the model\n",
    "- Vocabulary, language, and pipeline information built into the model.\n",
    "\n",
    "To install the model use the following command in Terminal:\n",
    "```python\n",
    "$ python -m spacy download en_core_web_sm\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the spacy small English model\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting Part-of-speech Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "She PRON\n",
      "ate VERB\n",
      "the DET\n",
      "pineapple NOUN\n",
      "pizza NOUN\n"
     ]
    }
   ],
   "source": [
    "# Example from spacy docs\n",
    "\n",
    "# Process the text using the small English model\n",
    "doc = nlp(\"She ate the pineapple pizza\")\n",
    "\n",
    "# Iterate over each token in the doc object\n",
    "for token in doc:\n",
    "    # For each token print the text and part-of-speech the tag is used.\n",
    "    # Using an attribute without an underscore will return an integer indicating the index.\n",
    "    print(token.text, token.pos_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting Syntactic Dependencies\n",
    "- `.text` returns the text of a token\n",
    "- `.pos_` returns the part of speech a word: Noun, verb, etc.\n",
    "- `dep_` returns the dependancy label of the token.\n",
    "- `.head.text` returns the parent token that the dependency. Shows the word that the token is attached to/dependant on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "She PRON nsubj ate\n",
      "ate VERB ROOT ate\n",
      "the DET det pizza\n",
      "pineapple NOUN compound pizza\n",
      "pizza NOUN dobj ate\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.text, token.pos_, token.dep_, token.head.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part-of-speech tag meaning\n",
    "- nsubj: nominal subject\n",
    "- det: determiner\n",
    "- dobj: direct object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting Named Entities\n",
    "Named entities are real world objects that are assigned a name, i.e. Apple\n",
    "\n",
    "__`spaCy`__ allows you to access named entities from a doc by using the `.ents` attibute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple ORG\n",
      "U.K. GPE\n",
      "$1 billion MONEY\n"
     ]
    }
   ],
   "source": [
    "# Process the text through the simple English model\n",
    "doc = nlp(\"Apple is looking at buying U.K. startup for $1 billion\")\n",
    "\n",
    "# Iterate over the entities in the doc object\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# spacy.explain method\n",
    "\n",
    "The `spacy.explain` method allows a user to get quick definitions of the most common tags and labels.\n",
    "\n",
    "Docstring: Get a description for a given POS tag, dependency label or entity type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Countries, cities, states'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Geopolitical entities\n",
    "spacy.explain('GPE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'noun, proper singular'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.explain('NNP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'compound'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.explain('compound')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'direct object'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.explain('dobj')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
