{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 3 Processing Pipelines\n",
    "\n",
    "This chapter will show you everything you need to know about spaCy's processing pipeline. You'll learn what goes on under the hood when you process a text, how to write your own components and add them to the pipeline, and how to use custom attributes to add your own metadata to the documents, spans and tokens.\n",
    "\n",
    "![spaCy pipeline](spacy_pipeline.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. In the first step of spaCy's pipeline, we need to pass text into a nlp object.\n",
    "    - Words, Sentences, __Text__\n",
    "2. Inside of the `nlp` object, the __tokenizer__ is applied to turn the string of text into a `Doc` object.\n",
    "3. Then the __tagger__, __parser__, and __ner__ (Entity recognizer) process the `Doc` object.\n",
    "4. Finally, a `Doc` object is returned.\n",
    "\n",
    "### Built-in pipeline components\n",
    "\n",
    "| __Name__    | __Description__        | __Creates__                                       |\n",
    "| :---------  | :--------------------- | :------------------------------------------------ |\n",
    "| __tagger__  | Part-of-speech tagger  | Token.tag, Token.pos                              |\n",
    "| __parser__  | Dependency parser      | Token.dep, Token.head, Doc.sents, Doc.noun_chunks |\n",
    "| __ner__     | Named Entity recgnizer | Doc.ents, Token.ent_iob, Token.ent_type           |\n",
    "| __textcat__ | Text classifier        | Doc.cats                                          |\n",
    "\n",
    "---\n",
    "### tagger\n",
    "The Part-of-speech tagger sets the `tag` attribute with the `POS` category the word/token belongs to:\n",
    "\n",
    "#### Alphabetical listing\n",
    "\n",
    "| POS   | Description              | Examples                                     |\n",
    "| :---- | :----------------------- | :------------------------------------------- |\n",
    "| ADJ   | adjective                | big, old, green, incomprehensible, first     |\n",
    "| ADP   | adposition               | in, to, during                               |\n",
    "| ADV   | adverb                   | very, tomorrow, down, where, there           |\n",
    "| AUX\t| auxiliary                | is, has (done), will (do), should (do)       |\n",
    "| CONJ  | conjunction              | and, or, but                                 |\n",
    "| CCONJ | coordinating conjunction | and, or, but                                 |\n",
    "| DET   | determiner\t           | a, an, the                                   |\n",
    "| INTJ  | interjection\t           | psst, ouch, bravo, hello                     |\n",
    "| NOUN  | noun\t                   | girl, cat, tree, air, beauty                 |\n",
    "| NUM   | numeral\t               | 1, 2017, one, seventy-seven, IV, MMXIV       |\n",
    "| PART  | particle\t               | ‚Äôs, not,                                     |\n",
    "| PRON  | pronoun\t               | I, you, he, she, myself, themselves, somebody|\n",
    "| PROPN | proper noun\t           | Mary, John, London, NATO, HBO                |\n",
    "| PUNCT | punctuation\t           | ., (, ), ?                                   |\n",
    "| SCONJ | subordinating conjunction| if, while, that                              |\n",
    "| SYM   | symbol\t               | $, %, ¬ß, ¬©, +, ‚àí, √ó, √∑, =, :), üòù            |\n",
    "| VERB  | verb                     | run, runs, running, eat, ate, eating         |\n",
    "| X     | other\t                   | sfpksdpsxmsa                                 |\n",
    "| SPACE | space\t                   | \" \"                                          |\n",
    "\n",
    "---\n",
    "### parser\n",
    "Dep: Syntactic dependency, i.e. the relation between tokens.\n",
    "\n",
    "### Universal Dependencies\n",
    "|      | ¬†                                            |\n",
    "| :--- | :------------------------------------------- |\n",
    "| acl  | clausal modifier of noun (adjectival clause) |\n",
    "| advcl | adverbial clause modifier\n",
    "| advmod | adverbial modifier\n",
    "| amod | adjectival modifier\n",
    "| appos | appositional modifier\n",
    "| aux | auxiliary\n",
    "| case | case marking\n",
    "| cc | coordinating conjunction\n",
    "| ccomp | clausal complement\n",
    "| clf | classifier\n",
    "| compound | compound\n",
    "| conj | conjunct\n",
    "| cop | copula\n",
    "| csubj | clausal subject\n",
    "| dep | unspecified dependency\n",
    "| det | determiner\n",
    "| discourse | discourse element\n",
    "| dislocated | dislocated elements\n",
    "| expl | expletive\n",
    "| fixed | fixed multiword expression\n",
    "| flat | flat multiword expression\n",
    "| goeswith | goes with\n",
    "| iobj | indirect object\n",
    "| list | list\n",
    "| mark | marker\n",
    "| nmod | nominal modifier\n",
    "| nsubj | nominal subject\n",
    "| nummod | numeric modifier\n",
    "| obj | object\n",
    "| obl | oblique nominal\n",
    "| orphan | orphan\n",
    "| parataxis | parataxis\n",
    "| punct | punctuation\n",
    "| reparandum | overridden disfluency\n",
    "| root | root\n",
    "| vocative | vocative\n",
    "| xcomp | open clausal complement |\n",
    "\n",
    "### English Dependencies\n",
    "|      |                                             |\n",
    "| :--- | :------------------------------------------ |\n",
    "| acl | clausal modifier of noun (adjectival clause) |\n",
    "| acomp | adjectival complement |\n",
    "| advcl | adverbial clause modifier |\n",
    "| advmod | adverbial modifier |\n",
    "| agent | agent |\n",
    "| amod | adjectival modifier |\n",
    "| appos | appositional modifier |\n",
    "| attr | attribute |\n",
    "| aux | auxiliary |\n",
    "| auxpass | auxiliary (passive) |\n",
    "| case | case marking |\n",
    "| cc | coordinating conjunction |\n",
    "| ccomp | clausal complement |\n",
    "| compound | compound |\n",
    "| conj | conjunct |\n",
    "| cop | copula |\n",
    "| csubj | clausal subject |\n",
    "| csubjpass | clausal subject (passive) |\n",
    "| dative | dative |\n",
    "| dep | unclassified dependent |\n",
    "| det | determiner |\n",
    "| dobj | direct object |\n",
    "| expl | expletive |\n",
    "| intj | interjection |\n",
    "| mark | marker |\n",
    "| meta | meta modifier |\n",
    "| neg | negation modifier |\n",
    "| nn | noun compound modifier |\n",
    "| nounmod | modifier of nominal |\n",
    "| npmod | noun phrase as adverbial modifier |\n",
    "| nsubj | nominal subject |\n",
    "| nsubjpass | nominal subject (passive) |\n",
    "| nummod | numeric modifier |\n",
    "| oprd | object predicate |\n",
    "| obj | object |\n",
    "| obl | oblique nominal |\n",
    "| parataxis | parataxis |\n",
    "| pcomp | complement of preposition |\n",
    "| pobj | object of preposition |\n",
    "| poss | possession modifier |\n",
    "| preconj | pre-correlative conjunction |\n",
    "| prep | prepositional modifier |\n",
    "| prt | particle |\n",
    "| punct | punctuation |\n",
    "| quantmod | modifier of quantifier |\n",
    "| relcl | relative clause modifier |\n",
    "| root | root |\n",
    "| xcomp | open clausal complement |\n",
    "    \n",
    "### ner, Named Entity Recognizer\n",
    "- The __entity recognizer__ adds the _detected_ entities to the `doc.ents` property.\n",
    "- The entity recognizer also sets the entity __type__ attributes on the tokens that indicate if a token is part of an entity or not.\n",
    "\n",
    "### textcat\n",
    "- The text classifier sets category labels that apply __to the whole text__, and adds them to the `doc.cats` property.\n",
    "- __Text categories are very specific. As a result, the text classifier is NOT included in any of the pre-trained models by default. It can be used to train your own systems.__\n",
    "\n",
    "## Under the hood\n",
    "- Pipeline defined in model's `meta.json` in order.\n",
    "    - The metafile defines the language (en, English) and pipeline.\n",
    "    - Tells spaCy which components to instantiate.\n",
    "- Built-in components need binary data to make predictions.\n",
    "    - The binary data used to make predictions is included in the model package. The data is loaded into the component when the model is loaded, `spacy.load(\"en_core_web_lg\")`\n",
    "    \n",
    "# What happens when you call nlp?\n",
    "What does spaCy do when you call nlp on a string of text?\n",
    "\n",
    "```python\n",
    "doc = nlp(\"This is a sentence.\")\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: Tokenize the text and apply each pipeline component in order.<br>\n",
    "tokenize -> tagger -> parser -> ner\n",
    "es an input stream into its component tokens.\n",
    "\n",
    "    That's correct!\n",
    "\n",
    "    The tokenizer turns a string of text into a Doc object. spaCy then applies every component in the pipeline on document, in order. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspecting the pipeline\n",
    "\n",
    "Let‚Äôs inspect the small English model‚Äôs pipeline!\n",
    "\n",
    "    Load the en_core_web_sm model and create the nlp object.\n",
    "    Print the names of the pipeline components using nlp.pipe_names.\n",
    "    Print the full pipeline of (name, component) tuples using nlp.pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m W&B installed but not logged in.  Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tok2vec', 'tagger', 'parser', 'ner', 'attribute_ruler', 'lemmatizer']\n",
      "[('tok2vec', <spacy.pipeline.tok2vec.Tok2Vec object at 0x7ff714848bf0>), ('tagger', <spacy.pipeline.tagger.Tagger object at 0x7ff71485f470>), ('parser', <spacy.pipeline.dep_parser.DependencyParser object at 0x7ff7145d2ad0>), ('ner', <spacy.pipeline.ner.EntityRecognizer object at 0x7ff7145d2c90>), ('attribute_ruler', <spacy.pipeline.attributeruler.AttributeRuler object at 0x7ff71488b190>), ('lemmatizer', <spacy.lang.en.lemmatizer.EnglishLemmatizer object at 0x7ff714867550>)]\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Load the en_core_web_lg model\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "\n",
    "# Print the names of the pipeline components\n",
    "print(nlp.pipe_names)\n",
    "\n",
    "# Print the full pipeline of (name, component) tuples\n",
    "print(nlp.pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    ‚úî Well done! Whenever you're unsure about the current pipeline, you can\n",
    "    inspect it by printing nlp.pipe_names or nlp.pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom pipeline components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
