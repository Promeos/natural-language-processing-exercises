{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Processing\n",
    "### Acquiring data from the internet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "from requests import get\n",
    "from time import time\n",
    "from time import sleep\n",
    "from random import randint\n",
    "from IPython.core.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By the end of this exercise, you should have a file named acquire.py that contains the specified functions. If you wish, you may break your work into separate files for each website (e.g. acquire_codeup_blog.py and acquire_news_articles.py), but the end function should be present in acquire.py (that is, acquire.py should import get_blog_articles from the acquire_codeup_blog module.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Codeup Blog Articles\n",
    "\n",
    "Scrape the article text from the following pages:\n",
    "\n",
    "    https://codeup.com/codeups-data-science-career-accelerator-is-here/\n",
    "    https://codeup.com/data-science-myths/\n",
    "    https://codeup.com/data-science-vs-data-analytics-whats-the-difference/\n",
    "    https://codeup.com/10-tips-to-crush-it-at-the-sa-tech-job-fair/\n",
    "    https://codeup.com/competitor-bootcamps-are-closing-is-the-model-in-danger/\n",
    "\n",
    "Encapsulate your work in a function named get_blog_articles that will return a list of dictionaries, with each dictionary representing one article. The shape of each dictionary should look like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "blog_url = 'https://codeup.com/codeups-data-science-career-accelerator-is-here/'\n",
    "headers = {\"User-Agent\": \"Codeup Data Science\"}\n",
    "response = get(blog_url, headers=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(response.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'September 30, 2018'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find('time', itemprop='datePublished').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "September 30, 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The rumors are true! The time has arrived. Codeup has officially opened applications to our new Data Science career accelerator, with only 25 seats available! This immersive program is one of a kind in San Antonio, and will help you land a job in\\xa0Glassdoor’s #1 Best Job in America.\\nData Science is a method of providing actionable intelligence from data.\\xa0The data revolution has hit San Antonio,\\xa0resulting in an explosion in Data Scientist positions\\xa0across companies like USAA, Accenture, Booz Allen Hamilton, and HEB. We’ve even seen\\xa0UTSA invest $70 M for a Cybersecurity Center and School of Data Science.\\xa0We built a program to specifically meet the growing demands of this industry.\\nOur program will be 18 weeks long, full-time, hands-on, and project-based. Our curriculum development and instruction is led by Senior Data Scientist, Maggie Giust, who has worked at HEB, Capital Group, and Rackspace, along with input from dozens of practitioners and hiring partners. Students will work with real data sets, realistic problems, and the entire data science pipeline from collection to deployment. They will receive professional development training in resume writing, interviewing, and continuing education to prepare for a smooth transition to the workforce.\\nWe focus on applied data science for immediate impact and ROI in a business, which is how we can back it all up with a 6 month tuition refund guarantee – just like our existing Web Dev program. We’re focusing on Data Science with Python, SQL, and ML, covered in\\xa014 modules: 1) Fundamentals; 2) Applied statistics; 3) SQL; 4) Python; 5) Supervised machine learning – regression; 6) Supervised machine learning – classification; 7) Unsupervised machine learning – clustering; 8) Time series analysis; 9) Anomaly detection; 10) Natural language processing; 11) Distributed machine learning; 12) Advanced topics (deep learning, NoSQL, cloud deployment, etc.); 13) Storytelling with data; and 14) Domain expertise development.\\nApplications are now open\\xa0for Codeup’s first Data Science cohort, which will start class on February 4, 2019. Hurry – there are only 25 seats available! To further our mission of cultivating inclusive growth, scholarships will be available to women, minorities, LGBTQIA+ individuals, veterans, first responders, and people relocating to San Antonio.\\nIf you want to learn about joining our program or hiring our graduates, email datascience@codeup.com!\\n\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find('div', class_='jupiterx-post-content').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_blog_articles():\n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "    file_name = 'blog_posts.csv'\n",
    "\n",
    "    if os.path.isfile(file_name):\n",
    "        return pd.read_csv(file_name, index_col=False)\n",
    "    \n",
    "    else:\n",
    "        requests = 0\n",
    "        start_time = time()\n",
    "        blog_posts = []\n",
    "        headers = {\"User-Agent\": \"Codeup Data Science\"}\n",
    "\n",
    "        blogs= ['https://codeup.com/codeups-data-science-career-accelerator-is-here/',\n",
    "                'https://codeup.com/data-science-myths/',\n",
    "                'https://codeup.com/data-science-vs-data-analytics-whats-the-difference/',\n",
    "                'https://codeup.com/10-tips-to-crush-it-at-the-sa-tech-job-fair/',\n",
    "                'https://codeup.com/competitor-bootcamps-are-closing-is-the-model-in-danger/']\n",
    "\n",
    "        for blog in blogs:\n",
    "            response = get(blog, headers=headers)\n",
    "\n",
    "            sleep(randint(1,3))\n",
    "            requests += 1\n",
    "            elapsed_time = time() - start_time\n",
    "\n",
    "            print('Request: {}; Frequency: {} requests/s'.format(requests, requests/elapsed_time))\n",
    "            clear_output(wait=True)\n",
    "\n",
    "            if response.status_code != 200:\n",
    "                warn(f\"Request{topic}, Status Code {response.status_code}\")\n",
    "\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "            title = soup.find('title').text\n",
    "            date_published = soup.find('time', itemprop='datePublished').text\n",
    "            article = soup.find('div', class_='jupiterx-post-content').text\n",
    "\n",
    "            blog_posts.append({'title': title,\n",
    "                               'date_published': date_published,\n",
    "                               'article': article})\n",
    "            \n",
    "        pd.DataFrame(blog_posts).to_csv(file_name)\n",
    "        return blog_posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'Codeup’s Data Science Career Accelerator is Here! - Codeup',\n",
       " 'date_published': 'September 30, 2018',\n",
       " 'article': 'The rumors are true! The time has arrived. Codeup has officially opened applications to our new Data Science career accelerator, with only 25 seats available! This immersive program is one of a kind in San Antonio, and will help you land a job in\\xa0Glassdoor’s #1 Best Job in America.\\nData Science is a method of providing actionable intelligence from data.\\xa0The data revolution has hit San Antonio,\\xa0resulting in an explosion in Data Scientist positions\\xa0across companies like USAA, Accenture, Booz Allen Hamilton, and HEB. We’ve even seen\\xa0UTSA invest $70 M for a Cybersecurity Center and School of Data Science.\\xa0We built a program to specifically meet the growing demands of this industry.\\nOur program will be 18 weeks long, full-time, hands-on, and project-based. Our curriculum development and instruction is led by Senior Data Scientist, Maggie Giust, who has worked at HEB, Capital Group, and Rackspace, along with input from dozens of practitioners and hiring partners. Students will work with real data sets, realistic problems, and the entire data science pipeline from collection to deployment. They will receive professional development training in resume writing, interviewing, and continuing education to prepare for a smooth transition to the workforce.\\nWe focus on applied data science for immediate impact and ROI in a business, which is how we can back it all up with a 6 month tuition refund guarantee – just like our existing Web Dev program. We’re focusing on Data Science with Python, SQL, and ML, covered in\\xa014 modules: 1) Fundamentals; 2) Applied statistics; 3) SQL; 4) Python; 5) Supervised machine learning – regression; 6) Supervised machine learning – classification; 7) Unsupervised machine learning – clustering; 8) Time series analysis; 9) Anomaly detection; 10) Natural language processing; 11) Distributed machine learning; 12) Advanced topics (deep learning, NoSQL, cloud deployment, etc.); 13) Storytelling with data; and 14) Domain expertise development.\\nApplications are now open\\xa0for Codeup’s first Data Science cohort, which will start class on February 4, 2019. Hurry – there are only 25 seats available! To further our mission of cultivating inclusive growth, scholarships will be available to women, minorities, LGBTQIA+ individuals, veterans, first responders, and people relocating to San Antonio.\\nIf you want to learn about joining our program or hiring our graduates, email datascience@codeup.com!\\n\\n'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_blog_articles()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inshorts: Stay Informed - Web Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = get('https://inshorts.com/en/read', headers=headers)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "article_containers = soup.find_all('div', class_='news-card z-depth-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# There are 25 news articles on each page.\n",
    "len(article_containers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Title')\n",
    "print(article_containers[0].find('span', itemprop='headline').text, end='\\n\\n')\n",
    "print('Article')\n",
    "print(article_containers[0].find('div', itemprop=\"articleBody\").text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_news_articles():\n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "    requests=0\n",
    "    file_name = 'news_articles.csv'\n",
    "\n",
    "    if os.path.isfile(file_name):\n",
    "        return pd.read_csv(file_name, index_col=False)\n",
    "    \n",
    "    else:\n",
    "        topics = ['business', 'sports', 'technology', 'entertainment']\n",
    "        collection = []\n",
    "        start_time = time()\n",
    "\n",
    "        for topic in topics:\n",
    "            inshorts_url = f'https://inshorts.com/en/read/{topic}'\n",
    "            headers = {'User_Agent': 'Promeos'}\n",
    "\n",
    "            response = get(inshorts_url, headers)\n",
    "\n",
    "            sleep(randint(1, 3))\n",
    "\n",
    "            requests += 1\n",
    "            elapsed_time = time() - start_time\n",
    "            print('Request: {}; Frequency: {} requests/s'.format(requests, requests/elapsed_time))\n",
    "            clear_output(wait=True)\n",
    "\n",
    "            if response.status_code != 200:\n",
    "                warn(f\"Request{response}, Status Code {response.status_code}\")\n",
    "\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "            article_containers = soup.find_all('div', class_='news-card z-depth-1')\n",
    "\n",
    "            for article in article_containers:\n",
    "                title = article.find('span', itemprop='headline').text\n",
    "                content = article.find('div', itemprop='articleBody').text\n",
    "                collection.append({'title': title,\n",
    "                                   'content': content,\n",
    "                                   'category': topic})\n",
    "            pd.DataFrame(collection).to_csv(file_name)\n",
    "    return collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': \"Moderna's early data shows its COVID-19 vaccine is 94.5% effective\",\n",
       " 'content': \"American biotechnology company Moderna on Monday announced its experimental vaccine was 94.5% effective in preventing COVID-19 based on interim data from a late-stage clinical trial. Moderna's interim analysis was based on 95 infections among trial participants who received either a placebo or the vaccine. Among those, only five infections occurred in those who received the vaccine.\",\n",
       " 'category': 'business'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_news_articles()[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
