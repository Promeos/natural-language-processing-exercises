{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping Fundamentals\n",
    "\n",
    "\n",
    "This notebook covers web scraping using Beautiful Soup.\n",
    "\n",
    "Data is abundant on the web. The data can be stored as a file, e.g. csv, xlsx, txt file, _or_ it can be __scraped from the web__.\n",
    "\n",
    "## Web scraping preparation\n",
    "1. Visit the webisite you want to scrape.\n",
    "2. Look at the HTML of the page to understand it's structure\n",
    "3. Copy the link to the webpage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries for web scraping\n",
    "from requests import get\n",
    "from bs4 import BeautifulSoup\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making the initial request: GET\n",
    "\n",
    "1. Copy and paste the webpage url into the jupyter notebook as a string. Assign the string to a variable named `url`.\n",
    "1. Specify the header as `{'User-Agent': 'Codeup Data Science'}`\n",
    "- If a header is _not_ specified an error is raised:<br>\n",
    ">__403 Error: Forbidden client error status response code indicates that the server understood the request but refuses to authorize it__. Or as Digital Ocean puts it \"4XX - Client Error (you messed up).\"\n",
    "3. Use the `get()` function. Pass the `url` as the first arguement and `headers` as the second arguement. Assign the function to a variable named `response` to store the result, the web-page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 : The web page we want to scrape\n",
    "url = 'https://codeup.com/codeups-data-science-career-accelerator-is-here/'\n",
    "\n",
    "# 2 : This must be a formal greeting to the server.\n",
    "headers = {'User-Agent': 'Codeup Data Science'} # Some websites don't accept the pyhon-requests default user-agent\n",
    "\n",
    "# 3 : Store the web page returned from the url request into a variable named repsonse.\n",
    "response = get(url, headers=headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Practices: Check the reponse object\n",
    "1. Check the status code of the Reponse object.\n",
    "- If the code is 200. The request was successful.\n",
    "- Anything else, look up the code and try again.\n",
    "2. Check the Response object content using `.text`\n",
    "- The web page contents will be displayed on screen, formatted as HTML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the status code to see if our request was fulfilled. 200 == Success.\n",
    "response.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html><html lang=\"en-US\"><head >\t<meta charset=\"UTF-8\" />\n",
      "\t<meta name=\"viewport\" content=\"width=device-width, initial-scale=1\" />\n",
      "\t\n",
      "\t<!-- This site is optimized with the Yoast SEO plugin v15.2.1 - https://yoast.com/wordpress/plugins/seo/ -->\n",
      "\t<title>Codeup’s Data Science Career Accelerator is Here! - Codeup</title>\n",
      "\t<meta name=\"description\" content=\"The rumors are true! The time has arriv\n"
     ]
    }
   ],
   "source": [
    "# The webpage we acquired is in HTML format.\n",
    "print(response.text[:400])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transforming the Response: Beautiful Soup\n",
    "\n",
    "Using Beautiful Soup we can add functionality to the body of text.\n",
    "1. Transform the Response object into a Beautiful Soup oject using `BeautifulSoup()`.\n",
    "- Pass the web page format as the prefix to .parser, in this case `html.parser`.\n",
    "\n",
    "Beautiful Soup Documents:<br>\n",
    "```python\n",
    "soup?\n",
    "'''\n",
    ":param markup: A string or a file-like object representing\n",
    " markup to be parsed.\n",
    "\n",
    ":param features: Desirable features of the parser to be\n",
    " used. This may be the name of a specific parser (\"lxml\",\n",
    " \"lxml-xml\", \"html.parser\", or \"html5lib\") or it may be the\n",
    " type of markup to be used (\"html\", \"html5\", \"xml\"). It's\n",
    " recommended that you name a specific parser, so that\n",
    " Beautiful Soup gives you the same results across platforms\n",
    " and virtual environments.'''\n",
    " ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the Response object as a Beautiful Soup Object.\n",
    "\n",
    "# Beautiful Soup(param markup == reponse.content, parser='html.paser')\n",
    "soup = BeautifulSoup(response.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing the contents of soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'html'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# soup.children returns an iterator object that allows us to see the\n",
    "#\n",
    "list(soup.children)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[bs4.element.Doctype, bs4.element.Tag]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[type(item) for item in list(soup.children)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-33f78714dc9c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msibling\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "list(soup.sibling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding Titles\n",
    "Using Beautiful Soup's `.find()` function you can access the HTML elements contained in a Beautiful Soup object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<title>Codeup’s Data Science Career Accelerator is Here! - Codeup</title>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find('title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Codeup’s Data Science Career Accelerator is Here! - Codeup'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.title.string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Codeup’s Data Science Career Accelerator is Here! - Codeup'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find('title').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Codeup’s Data Science Career Accelerator is Here! - Codeup'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find('title').get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Codeup’s Data Science Career Accelerator is Here! - Codeup'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find('title').string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding Headings\n",
    "\n",
    "Using Beautiful Soup's `.find()` function you can access the HTML elements contained in the Beautiful Soup object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<h1 class=\"jupiterx-post-title\" itemprop=\"headline\">Codeup’s Data Science Career Accelerator is Here!</h1>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find('h1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Codeup’s Data Science Career Accelerator is Here!'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.h1.string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Codeup’s Data Science Career Accelerator is Here!'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find('h1', class_='jupiterx-post-title').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Codeup’s Data Science Career Accelerator is Here!'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find('h1').get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Codeup’s Data Science Career Accelerator is Here!'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find('h1').string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.h1.string == soup.find('h1').text == soup.find('h1').string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Article\n",
    "Using `soup.find()` is useful. In an HTML file there are multiple \\<div> classes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The rumors are true! The time has arrived. Codeup has officially opened applications to our new Data Science career accelerator, with only 25 seats available! This immersive program is one of a kind in San Antonio, and will help you land a job in Glassdoor’s #1 Best Job in America.\n",
      "Data Science is a method of providing actionable intelligence from data. The data revolution has hit San Antonio, resulting in an explosion in Data Scientist positions across companies like USAA, Accenture, Booz Allen Hamilton, and HEB. We’ve even seen UTSA invest $70 M for a Cybersecurity Center and School of Data Science. We built a program to specifically meet the growing demands of this industry.\n",
      "Our program will be 18 weeks long, full-time, hands-on, and project-based. Our curriculum development and instruction is led by Senior Data Scientist, Maggie Giust, who has worked at HEB, Capital Group, and Rackspace, along with input from dozens of practitioners and hiring partners. Students will work with real data sets, realistic problems, and the entire data science pipeline from collection to deployment. They will receive professional development training in resume writing, interviewing, and continuing education to prepare for a smooth transition to the workforce.\n",
      "We focus on applied data science for immediate impact and ROI in a business, which is how we can back it all up with a 6 month tuition refund guarantee – just like our existing Web Dev program. We’re focusing on Data Science with Python, SQL, and ML, covered in 14 modules: 1) Fundamentals; 2) Applied statistics; 3) SQL; 4) Python; 5) Supervised machine learning – regression; 6) Supervised machine learning – classification; 7) Unsupervised machine learning – clustering; 8) Time series analysis; 9) Anomaly detection; 10) Natural language processing; 11) Distributed machine learning; 12) Advanced topics (deep learning, NoSQL, cloud deployment, etc.); 13) Storytelling with data; and 14) Domain expertise development.\n",
      "Applications are now open for Codeup’s first Data Science cohort, which will start class on February 4, 2019. Hurry – there are only 25 seats available! To further our mission of cultivating inclusive growth, scholarships will be available to women, minorities, LGBTQIA+ individuals, veterans, first responders, and people relocating to San Antonio.\n",
      "If you want to learn about joining our program or hiring our graduates, email datascience@codeup.com!\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "article = soup.find('div', class_='jupiterx-post-content')\n",
    "\n",
    "# access the text strored in article.\n",
    "print(article.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# Write the text stored in `article` to a file named `article.txt.\n",
    "with open('article.txt', 'w') as f:\n",
    "    f.write(article.text)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_article_text():\n",
    "    '''\n",
    "    This function retrieves data scraped from:\n",
    "    \n",
    "    https://codeup.com/codeups-data-science-career-accelerator-is-here/\n",
    "    \n",
    "    Returns the contents of tag: <div class=jupiterx-post-content> as a string.\n",
    "    '''\n",
    "    # check to see the file exists. If it does open it\n",
    "    # and return the contents as a string.\n",
    "    sys.path.insert(1, '../data/')\n",
    "\n",
    "    if os.path.exists('data/article.txt'):\n",
    "        with open('article.txt') as f:\n",
    "            return f.read()\n",
    "\n",
    "    # otherwise fetch the data\n",
    "    url = 'https://codeup.com/codeups-data-science-career-accelerator-is-here/'\n",
    "    headers = {'User-Agent': 'Codeup Data Science'}\n",
    "    response = get(url, headers=headers)\n",
    "    soup = BeautifulSoup(response.text)\n",
    "    article = soup.find('div', class_='jupiterx-post-content')\n",
    "\n",
    "    # cache the data locally\n",
    "    with open('article.txt', 'w') as f:\n",
    "        f.write(article.text)\n",
    "\n",
    "    # return the contents of article as a string.\n",
    "    return article.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking the Response object headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Server': 'nginx', 'Date': 'Fri, 13 Nov 2020 23:29:38 GMT', 'Content-Type': 'text/html; charset=UTF-8', 'Transfer-Encoding': 'chunked', 'Connection': 'keep-alive', 'Keep-Alive': 'timeout=20', 'Vary': 'Accept-Encoding, Accept-Encoding, Accept-Encoding,Cookie', 'Link': '<https://codeup.com/wp-json/>; rel=\"https://api.w.org/\", <https://codeup.com/wp-json/wp/v2/posts/619>; rel=\"alternate\"; type=\"application/json\", <https://codeup.com/?p=619>; rel=shortlink', 'X-Powered-By': 'WP Engine', 'X-Cacheable': 'SHORT', 'Cache-Control': 'max-age=600, must-revalidate', 'X-Cache': 'HIT: 3', 'X-Cache-Group': 'normal', 'Content-Encoding': 'gzip'}\n"
     ]
    }
   ],
   "source": [
    "# Checking to see what headers represents/means\n",
    "print(response.headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bytes"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Displays the entire web page.\n",
    "# Interesting. The content has a memory value.\n",
    "type(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beautiful Soup Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<h2 class=\"jupiterx-post-related-label\">Recommended Posts</h2>]\n"
     ]
    }
   ],
   "source": [
    "# Heading 2\n",
    "print(soup.find_all('h2'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# Extracting div class\n",
    "soup.div.extract?\n",
    "```\n",
    "\n",
    "Wow.\n",
    "```python'''\n",
    "Signature: soup.div.extract()\n",
    "Docstring:\n",
    "Destructively rips this element out of the tree.\n",
    "\n",
    ":return: `self`, no longer part of the tree.'''\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
